{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/Mycode/raw_data/train.csv\")\n",
    "train.index=train[\"Id\"]\n",
    "train.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1459 entries, 0 to 1458\nData columns (total 80 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Id             1459 non-null   int64  \n 1   MSSubClass     1459 non-null   int64  \n 2   MSZoning       1455 non-null   object \n 3   LotFrontage    1232 non-null   float64\n 4   LotArea        1459 non-null   int64  \n 5   Street         1459 non-null   object \n 6   Alley          107 non-null    object \n 7   LotShape       1459 non-null   object \n 8   LandContour    1459 non-null   object \n 9   Utilities      1457 non-null   object \n 10  LotConfig      1459 non-null   object \n 11  LandSlope      1459 non-null   object \n 12  Neighborhood   1459 non-null   object \n 13  Condition1     1459 non-null   object \n 14  Condition2     1459 non-null   object \n 15  BldgType       1459 non-null   object \n 16  HouseStyle     1459 non-null   object \n 17  OverallQual    1459 non-null   int64  \n 18  OverallCond    1459 non-null   int64  \n 19  YearBuilt      1459 non-null   int64  \n 20  YearRemodAdd   1459 non-null   int64  \n 21  RoofStyle      1459 non-null   object \n 22  RoofMatl       1459 non-null   object \n 23  Exterior1st    1458 non-null   object \n 24  Exterior2nd    1458 non-null   object \n 25  MasVnrType     1443 non-null   object \n 26  MasVnrArea     1444 non-null   float64\n 27  ExterQual      1459 non-null   object \n 28  ExterCond      1459 non-null   object \n 29  Foundation     1459 non-null   object \n 30  BsmtQual       1415 non-null   object \n 31  BsmtCond       1414 non-null   object \n 32  BsmtExposure   1415 non-null   object \n 33  BsmtFinType1   1417 non-null   object \n 34  BsmtFinSF1     1458 non-null   float64\n 35  BsmtFinType2   1417 non-null   object \n 36  BsmtFinSF2     1458 non-null   float64\n 37  BsmtUnfSF      1458 non-null   float64\n 38  TotalBsmtSF    1458 non-null   float64\n 39  Heating        1459 non-null   object \n 40  HeatingQC      1459 non-null   object \n 41  CentralAir     1459 non-null   object \n 42  Electrical     1459 non-null   object \n 43  1stFlrSF       1459 non-null   int64  \n 44  2ndFlrSF       1459 non-null   int64  \n 45  LowQualFinSF   1459 non-null   int64  \n 46  GrLivArea      1459 non-null   int64  \n 47  BsmtFullBath   1457 non-null   float64\n 48  BsmtHalfBath   1457 non-null   float64\n 49  FullBath       1459 non-null   int64  \n 50  HalfBath       1459 non-null   int64  \n 51  BedroomAbvGr   1459 non-null   int64  \n 52  KitchenAbvGr   1459 non-null   int64  \n 53  KitchenQual    1458 non-null   object \n 54  TotRmsAbvGrd   1459 non-null   int64  \n 55  Functional     1457 non-null   object \n 56  Fireplaces     1459 non-null   int64  \n 57  FireplaceQu    729 non-null    object \n 58  GarageType     1383 non-null   object \n 59  GarageYrBlt    1381 non-null   float64\n 60  GarageFinish   1381 non-null   object \n 61  GarageCars     1458 non-null   float64\n 62  GarageArea     1458 non-null   float64\n 63  GarageQual     1381 non-null   object \n 64  GarageCond     1381 non-null   object \n 65  PavedDrive     1459 non-null   object \n 66  WoodDeckSF     1459 non-null   int64  \n 67  OpenPorchSF    1459 non-null   int64  \n 68  EnclosedPorch  1459 non-null   int64  \n 69  3SsnPorch      1459 non-null   int64  \n 70  ScreenPorch    1459 non-null   int64  \n 71  PoolArea       1459 non-null   int64  \n 72  PoolQC         3 non-null      object \n 73  Fence          290 non-null    object \n 74  MiscFeature    51 non-null     object \n 75  MiscVal        1459 non-null   int64  \n 76  MoSold         1459 non-null   int64  \n 77  YrSold         1459 non-null   int64  \n 78  SaleType       1458 non-null   object \n 79  SaleCondition  1459 non-null   object \ndtypes: float64(11), int64(26), object(43)\nmemory usage: 912.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# test=train.drop(\"SalePrice\",axis=1)\n",
    "test=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/test.csv\")\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\n",
    "quantitative.remove('SalePrice')\n",
    "# quantitative.remove('Id')\n",
    "qualitative = [f for f in train.columns if train.dtypes[f] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['MSZoning_E', 'Street_E', 'Alley_E', 'LotShape_E', 'LandContour_E', 'Utilities_E', 'LotConfig_E', 'LandSlope_E', 'Neighborhood_E', 'Condition1_E', 'Condition2_E', 'BldgType_E', 'HouseStyle_E', 'RoofStyle_E', 'RoofMatl_E', 'Exterior1st_E', 'Exterior2nd_E', 'MasVnrType_E', 'ExterQual_E', 'ExterCond_E', 'Foundation_E', 'BsmtQual_E', 'BsmtCond_E', 'BsmtExposure_E', 'BsmtFinType1_E', 'BsmtFinType2_E', 'Heating_E', 'HeatingQC_E', 'CentralAir_E', 'Electrical_E', 'KitchenQual_E', 'Functional_E', 'FireplaceQu_E', 'GarageType_E', 'GarageFinish_E', 'GarageQual_E', 'GarageCond_E', 'PavedDrive_E', 'PoolQC_E', 'Fence_E', 'MiscFeature_E', 'SaleType_E', 'SaleCondition_E']\n"
     ]
    }
   ],
   "source": [
    "def encode(frame, feature):\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique()\n",
    "    ordering.index = ordering.val\n",
    "    ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n",
    "    ordering = ordering.sort_values('spmean')\n",
    "    ordering['ordering'] = range(1, ordering.shape[0]+1)\n",
    "    ordering = ordering['ordering'].to_dict()\n",
    "    \n",
    "    for cat, o in ordering.items():\n",
    "        frame.loc[frame[feature] == cat, feature+'_E'] = o\n",
    "    \n",
    "qual_encoded = []\n",
    "for q in qualitative:  \n",
    "    encode(train, q)\n",
    "    qual_encoded.append(q+'_E')\n",
    "print(qual_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.GrLivArea < 4500]#GrLivArea: Above grade (ground) living area square feet\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "y = train['SalePrice'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为什么这里要被drop掉\n",
    "# train_features = train.drop(['SalePrice'], axis=1)\n",
    "train_features=train\n",
    "test_features = test\n",
    "# 把train_features和test_features拼在一起\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['MSSubClass'] = features['MSSubClass'].apply(str)# numerical -> categorical\n",
    "features['YrSold'] = features['YrSold'].astype(str)# numerical -> categorical\n",
    "features['MoSold'] = features['MoSold'].astype(str)# numerical -> categorical\n",
    "features['Functional'] = features['Functional'].fillna('Typ') #Home functionality (Assume typical unless deductions are warranted)\n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\") #   SBrkr\tStandard Circuit Breakers & Romex\n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\") #Typical/Average\n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")#没有就是没有泳池\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0]) #Exterior covering on house\n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n",
    "# Exterior covering on house\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageYrBlt是因为没有车库还是缺失？\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')\n",
    "#MSSubClass: Identifies the type of dwelling involved in the sale.\t将MSZoning和MSSubClass相关联\n",
    "features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)\n",
    "features.update(features[objects].fillna('None'))\n",
    "#LotFrontage: Linear feet of street connected to property\n",
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/site-packages/scipy/stats/stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n/usr/local/lib/python3.8/site-packages/scipy/stats/stats.py:3875: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "# skew_features处理\n",
    "# skew_features的skewness>0.5的就用boxcox变换处理\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "# ？Q\n",
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinations of existing features\n",
    "features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)# 为什么这个feature要drop？是要一个个尝试吗\n",
    "\n",
    "features['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\n",
    "features['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "\n",
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "features['EnclosedPorch'] + features['ScreenPorch'] +features['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2917, 131)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2917, 378)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "final_features = pd.get_dummies(features).reset_index(drop=True)\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_features.to_csv(\"kaggelOnlineTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1458, 378), (1458,), (1459, 378))"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "X = final_features.iloc[:len(y), :]\n",
    "X_sub = final_features.iloc[len(y):, :]\n",
    "X.shape, y.shape, X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]#?\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])\n",
    "\n",
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "X = X.drop(overfit, axis=1)\n",
    "X_sub = X_sub.drop(overfit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1453, 376)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"kaggleOnlineTrainDataSet.csv\")\n",
    "X_sub.to_csv(\"kaggleOnlineTestDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1459, 376)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-27-6aaf1f276005>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                               \n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.01,n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(ridge)\n",
    "score = cv_rmse(lasso)\n",
    "print(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "START Fit\n",
      "stack_gen\n",
      "[15:18:40] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:18:50] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:19:01] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:19:14] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:19:26] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[15:20:15] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:20:44] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "elasticnet\n",
      "Lasso\n",
      "Ridge\n",
      "Svr\n",
      "GradientBoosting\n",
      "xgboost\n",
      "[15:21:24] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "lightgbm\n"
     ]
    }
   ],
   "source": [
    "print('START Fit')\n",
    "\n",
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
    "\n",
    "print('elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print('Lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "\n",
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.05 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.3 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSLE score on train data:\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "0.007698944070475055\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predict submission\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('Predict submission')\n",
    "submission = pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/sample_submission (1).csv\")\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Blend with Top Kernels submissions\\n')\n",
    "# sub_1 = pd.read_csv('../input/top-10-0-10943-stacking-mice-and-brutal-force/House_Prices_submit.csv')\n",
    "# sub_2 = pd.read_csv('../input/hybrid-svm-benchmark-approach-0-11180-lb-top-2/hybrid_solution.csv')\n",
    "# sub_3 = pd.read_csv('../input/lasso-model-for-regression-problem/lasso_sol22_Median.csv')\n",
    "# submission.iloc[:,1] = np.floor((0.25 * np.floor(np.expm1(blend_models_predict(X_sub)))) + \n",
    "#                                 (0.25 * sub_1.iloc[:,1]) + \n",
    "#                                 (0.25 * sub_2.iloc[:,1]) + \n",
    "#                                 (0.25 * sub_3.iloc[:,1]))"
   ]
  }
 ]
}