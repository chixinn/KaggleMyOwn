{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/Mycode/raw_data/train.csv\")\n",
    "train.index=train[\"Id\"]\n",
    "train.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1460 entries, 1 to 1460\nData columns (total 79 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   MSSubClass     1460 non-null   int64  \n 1   MSZoning       1460 non-null   object \n 2   LotFrontage    1201 non-null   float64\n 3   LotArea        1460 non-null   int64  \n 4   Street         1460 non-null   object \n 5   Alley          91 non-null     object \n 6   LotShape       1460 non-null   object \n 7   LandContour    1460 non-null   object \n 8   Utilities      1460 non-null   object \n 9   LotConfig      1460 non-null   object \n 10  LandSlope      1460 non-null   object \n 11  Neighborhood   1460 non-null   object \n 12  Condition1     1460 non-null   object \n 13  Condition2     1460 non-null   object \n 14  BldgType       1460 non-null   object \n 15  HouseStyle     1460 non-null   object \n 16  OverallQual    1460 non-null   int64  \n 17  OverallCond    1460 non-null   int64  \n 18  YearBuilt      1460 non-null   int64  \n 19  YearRemodAdd   1460 non-null   int64  \n 20  RoofStyle      1460 non-null   object \n 21  RoofMatl       1460 non-null   object \n 22  Exterior1st    1460 non-null   object \n 23  Exterior2nd    1460 non-null   object \n 24  MasVnrType     1452 non-null   object \n 25  MasVnrArea     1452 non-null   float64\n 26  ExterQual      1460 non-null   object \n 27  ExterCond      1460 non-null   object \n 28  Foundation     1460 non-null   object \n 29  BsmtQual       1423 non-null   object \n 30  BsmtCond       1423 non-null   object \n 31  BsmtExposure   1422 non-null   object \n 32  BsmtFinType1   1423 non-null   object \n 33  BsmtFinSF1     1460 non-null   int64  \n 34  BsmtFinType2   1422 non-null   object \n 35  BsmtFinSF2     1460 non-null   int64  \n 36  BsmtUnfSF      1460 non-null   int64  \n 37  TotalBsmtSF    1460 non-null   int64  \n 38  Heating        1460 non-null   object \n 39  HeatingQC      1460 non-null   object \n 40  CentralAir     1460 non-null   object \n 41  Electrical     1459 non-null   object \n 42  1stFlrSF       1460 non-null   int64  \n 43  2ndFlrSF       1460 non-null   int64  \n 44  LowQualFinSF   1460 non-null   int64  \n 45  GrLivArea      1460 non-null   int64  \n 46  BsmtFullBath   1460 non-null   int64  \n 47  BsmtHalfBath   1460 non-null   int64  \n 48  FullBath       1460 non-null   int64  \n 49  HalfBath       1460 non-null   int64  \n 50  BedroomAbvGr   1460 non-null   int64  \n 51  KitchenAbvGr   1460 non-null   int64  \n 52  KitchenQual    1460 non-null   object \n 53  TotRmsAbvGrd   1460 non-null   int64  \n 54  Functional     1460 non-null   object \n 55  Fireplaces     1460 non-null   int64  \n 56  FireplaceQu    770 non-null    object \n 57  GarageType     1379 non-null   object \n 58  GarageYrBlt    1379 non-null   float64\n 59  GarageFinish   1379 non-null   object \n 60  GarageCars     1460 non-null   int64  \n 61  GarageArea     1460 non-null   int64  \n 62  GarageQual     1379 non-null   object \n 63  GarageCond     1379 non-null   object \n 64  PavedDrive     1460 non-null   object \n 65  WoodDeckSF     1460 non-null   int64  \n 66  OpenPorchSF    1460 non-null   int64  \n 67  EnclosedPorch  1460 non-null   int64  \n 68  3SsnPorch      1460 non-null   int64  \n 69  ScreenPorch    1460 non-null   int64  \n 70  PoolArea       1460 non-null   int64  \n 71  PoolQC         7 non-null      object \n 72  Fence          281 non-null    object \n 73  MiscFeature    54 non-null     object \n 74  MiscVal        1460 non-null   int64  \n 75  MoSold         1460 non-null   int64  \n 76  YrSold         1460 non-null   int64  \n 77  SaleType       1460 non-null   object \n 78  SaleCondition  1460 non-null   object \ndtypes: float64(3), int64(33), object(43)\nmemory usage: 912.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test=train.drop(\"SalePrice\",axis=1)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\n",
    "quantitative.remove('SalePrice')\n",
    "# quantitative.remove('Id')\n",
    "qualitative = [f for f in train.columns if train.dtypes[f] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['MSZoning_E', 'Street_E', 'Alley_E', 'LotShape_E', 'LandContour_E', 'Utilities_E', 'LotConfig_E', 'LandSlope_E', 'Neighborhood_E', 'Condition1_E', 'Condition2_E', 'BldgType_E', 'HouseStyle_E', 'RoofStyle_E', 'RoofMatl_E', 'Exterior1st_E', 'Exterior2nd_E', 'MasVnrType_E', 'ExterQual_E', 'ExterCond_E', 'Foundation_E', 'BsmtQual_E', 'BsmtCond_E', 'BsmtExposure_E', 'BsmtFinType1_E', 'BsmtFinType2_E', 'Heating_E', 'HeatingQC_E', 'CentralAir_E', 'Electrical_E', 'KitchenQual_E', 'Functional_E', 'FireplaceQu_E', 'GarageType_E', 'GarageFinish_E', 'GarageQual_E', 'GarageCond_E', 'PavedDrive_E', 'PoolQC_E', 'Fence_E', 'MiscFeature_E', 'SaleType_E', 'SaleCondition_E']\n"
     ]
    }
   ],
   "source": [
    "def encode(frame, feature):\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique()\n",
    "    ordering.index = ordering.val\n",
    "    ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n",
    "    ordering = ordering.sort_values('spmean')\n",
    "    ordering['ordering'] = range(1, ordering.shape[0]+1)\n",
    "    ordering = ordering['ordering'].to_dict()\n",
    "    \n",
    "    for cat, o in ordering.items():\n",
    "        frame.loc[frame[feature] == cat, feature+'_E'] = o\n",
    "    \n",
    "qual_encoded = []\n",
    "for q in qualitative:  \n",
    "    encode(train, q)\n",
    "    qual_encoded.append(q+'_E')\n",
    "print(qual_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.GrLivArea < 4500]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "y = train['SalePrice'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "test_features = test\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['MSSubClass'] = features['MSSubClass'].apply(str)\n",
    "features['YrSold'] = features['YrSold'].astype(str)\n",
    "features['MoSold'] = features['MoSold'].astype(str)\n",
    "features['Functional'] = features['Functional'].fillna('Typ') \n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\") \n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\") \n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0]) \n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')\n",
    "\n",
    "features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)\n",
    "features.update(features[objects].fillna('None'))\n",
    "\n",
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/site-packages/scipy/stats/stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n/usr/local/lib/python3.8/site-packages/scipy/stats/stats.py:3875: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "\n",
    "features['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\n",
    "features['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "\n",
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n",
    "                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                              features['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2918, 129)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2918, 376)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "final_features = pd.get_dummies(features).reset_index(drop=True)\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_features.to_csv(\"kaggelOnlineTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1458, 376), (1458,), (1460, 376))"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "X = final_features.iloc[:len(y), :]\n",
    "X_sub = final_features.iloc[len(y):, :]\n",
    "X.shape, y.shape, X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]#?\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])\n",
    "\n",
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "X = X.drop(overfit, axis=1)\n",
    "X_sub = X_sub.drop(overfit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.01,n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LASSO: 0.1003 (0.0147)\n",
      " 2021-05-10 10:54:55.800914\n",
      "elastic net: 0.1004 (0.0146)\n",
      " 2021-05-10 10:55:51.518173\n",
      "SVR: 0.1062 (0.0084)\n",
      " 2021-05-10 10:56:02.802426\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "lightgbm: 0.1056 (0.0154)\n",
      " 2021-05-10 10:56:47.716837\n",
      "gbr: 0.1084 (0.0135)\n",
      " 2021-05-10 10:58:17.663396\n",
      "[10:58:17] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[10:58:33] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[10:58:51] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[10:59:09] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[10:59:34] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[10:59:55] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[11:00:13] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[11:00:31] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[11:00:49] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "[11:01:07] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "xgboost: 0.1041 (0.0153)\n",
      " 2021-05-10 11:01:24.200976\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(ridge)\n",
    "score = cv_rmse(lasso)\n",
    "print(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "START Fit\n",
      "stack_gen\n",
      "[11:06:16] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:06:29] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:06:46] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:07:01] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:07:15] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[11:07:46] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:08:17] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "elasticnet\n",
      "Lasso\n",
      "Ridge\n",
      "Svr\n",
      "GradientBoosting\n",
      "xgboost\n",
      "[11:08:51] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "lightgbm\n"
     ]
    }
   ],
   "source": [
    "print('START Fit')\n",
    "\n",
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
    "\n",
    "print('elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print('Lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "\n",
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.05 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.3 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSLE score on train data:\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "0.0530594976263883\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predict submission\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot set using a multi-index selection indexer with a different length than the value",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e5e1d0f2fa3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predict submission'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/sample_submission (1).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblend_models_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1664\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlplane_indexer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m                     \u001b[0;31m# Exclude zero-len for e.g. boolean masking that is all-false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1667\u001b[0m                         \u001b[0;34m\"cannot set using a multi-index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                         \u001b[0;34m\"selection indexer with a different \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set using a multi-index selection indexer with a different length than the value"
     ]
    }
   ],
   "source": [
    "print('Predict submission')\n",
    "submission = pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/sample_submission (1).csv\")\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Blend with Top Kernels submissions\\n')\n",
    "sub_1 = pd.read_csv('../input/top-10-0-10943-stacking-mice-and-brutal-force/House_Prices_submit.csv')\n",
    "sub_2 = pd.read_csv('../input/hybrid-svm-benchmark-approach-0-11180-lb-top-2/hybrid_solution.csv')\n",
    "sub_3 = pd.read_csv('../input/lasso-model-for-regression-problem/lasso_sol22_Median.csv')\n",
    "submission.iloc[:,1] = np.floor((0.25 * np.floor(np.expm1(blend_models_predict(X_sub)))) + \n",
    "                                (0.25 * sub_1.iloc[:,1]) + \n",
    "                                (0.25 * sub_2.iloc[:,1]) + \n",
    "                                (0.25 * sub_3.iloc[:,1]))"
   ]
  }
 ]
}