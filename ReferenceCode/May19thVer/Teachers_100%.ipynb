{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "how many data has missing value = 33\n"
     ]
    }
   ],
   "source": [
    "##COPYRIGHT from 仲益教育\n",
    "\n",
    "##Part 1: Data Exploration\n",
    "#0.0: import packages\n",
    "#pandas is a data structure package\n",
    "#seaborn is a statistial data visualization\n",
    "#matplotlib is a plotting package\n",
    "#numpy is a scientific calculation in Python\n",
    "#sklearn is a data science package\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import sys\n",
    "\n",
    "#0.1: import data\n",
    "#change to your local path\n",
    "train_data=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/house-prices-advanced-regression-techniques/train.csv\")\n",
    "test_data=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/house-prices-advanced-regression-techniques/test.csv\")\n",
    "train_data=test_data\n",
    "#1.1: look at what's in the data\n",
    "train_data.columns\n",
    "#look at data description, look at variable table\n",
    "#or use excel to look at the data\n",
    "#or use the following useful functions\n",
    "train_data.shape\n",
    "train_data.head()\n",
    "train_data.tail()\n",
    "#Change dataframe index to Id\n",
    "train_data.index=train_data[\"Id\"]\n",
    "train_data.drop(\"Id\", axis=1, inplace=True)\n",
    "\n",
    "# #2.1: look at what do we need to predict first\n",
    "# #decriptive summary, look at the distribution of data\n",
    "# train_data[\"SalePrice\"].describe()\n",
    "# #skewness and kurtosis\n",
    "# print(\"Skewness: %f\" % train_data['SalePrice'].skew())\n",
    "# print(\"Kurtosis: %f\" % train_data['SalePrice'].kurt())\n",
    "# #histogram\n",
    "# sns.distplot(train_data['SalePrice'])\n",
    "\n",
    "# #2.2: look at what are the variables\n",
    "# #select some variables you think are relevant\n",
    "# #2.2.1 numerical variables: try LotArea (lot size in square feet) and year built\n",
    "# #scatter plot\n",
    "# var = 'LotArea'\n",
    "# data = pd.concat([train_data['SalePrice'], train_data[var]], axis=1)\n",
    "# data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));\n",
    "# var = 'YearBuilt'\n",
    "# data = pd.concat([train_data['SalePrice'], train_data[var]], axis=1)\n",
    "# data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));\n",
    "# #2.2.2 categorical variables: try OverQual (Overall material and finish quality)\n",
    "# #boxplot\n",
    "# var = 'OverallQual'\n",
    "# data = pd.concat([train_data['SalePrice'], train_data[var]], axis=1)\n",
    "# f, ax = plt.subplots(figsize=(8, 6))\n",
    "# fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "# fig.axis(ymin=0, ymax=800000);\n",
    "# #2.2.3 correlation\n",
    "# #heat map\n",
    "# corrmat = train_data.corr()\n",
    "# f, ax = plt.subplots(figsize=(12, 9))\n",
    "# sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "# #top correlated variables\n",
    "# k = 10 #number of variables for heatmap\n",
    "# cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "# cm = np.corrcoef(train_data[cols].values.T)\n",
    "# sns.set(font_scale=1.25)\n",
    "# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, \n",
    "#                  yticklabels=cols.values, xticklabels=cols.values)\n",
    "# plt.show()\n",
    "# #scatter plot \n",
    "# sns.set()\n",
    "# cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF']\n",
    "# sns.pairplot(train_data[cols], height = 2.5)\n",
    "# plt.show();\n",
    "\n",
    "#3.1 data cleaning: no correct answer\n",
    "# how many % of data are missing\n",
    "total = train_data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "print(\"how many data has missing value = \" + str(sum(missing_data['Total'] >= 1)))\n",
    "#3.1.1 fill missing value with mode\n",
    "train_data[\"Electrical\"]=train_data[\"Electrical\"].fillna(train_data[\"Electrical\"].mode()[0])\n",
    "#3.1.2 fill missing value with 0\n",
    "train_data[\"MasVnrArea\"]=train_data[\"MasVnrArea\"].fillna(0)\n",
    "#3.1.3 OR fill missing value with None\n",
    "train_data[\"MasVnrArea\"]=train_data[\"MasVnrArea\"].fillna(\"None\")\n",
    "#3.1.4 OR fill missing value with median\n",
    "train_data[\"MasVnrArea\"]=train_data[\"MasVnrArea\"].fillna(train_data[\"MasVnrArea\"].median())\n",
    "\n",
    "#3.1.5 #dealing with missing data\n",
    "#need to understand\n",
    "total = train_data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "train_data = train_data.drop((missing_data[missing_data['Total'] >= 1]).index,1)\n",
    "#just checking that there's no missing data missing\n",
    "train_data.isnull().sum().max() \n",
    "\n",
    "# #3.2 outliers\n",
    "# #z-score\n",
    "# saleprice_scaled = StandardScaler().fit_transform(train_data['SalePrice'][:,np.newaxis]);\n",
    "# low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\n",
    "# high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\n",
    "# print('outer range (low) of the distribution:')\n",
    "# print(low_range)\n",
    "# print('\\nouter range (high) of the distribution:')\n",
    "# print(high_range)\n",
    "# #scatter chart\n",
    "# var = 'GrLivArea'\n",
    "# data = pd.concat([train_data['SalePrice'], train_data[var]], axis=1)\n",
    "# data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));\n",
    "# #3.2.1 deleting points\n",
    "# train_data.sort_values(by = 'GrLivArea', ascending = False)[:2]\n",
    "# # train_data = train_data.drop(1299)\n",
    "# # train_data = train_data.drop(524)\n",
    "# var = 'TotalBsmtSF'\n",
    "# data = pd.concat([train_data['SalePrice'], train_data[var]], axis=1)\n",
    "# data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));\n",
    "# #3.2.2 log transformation\n",
    "# #histogram and normal probability plot\n",
    "# print(\"Skewness: %f\" % train_data['SalePrice'].skew())\n",
    "# print(\"Kurtosis: %f\" % train_data['SalePrice'].kurt())\n",
    "# sns.distplot(train_data['SalePrice'], fit=norm);\n",
    "# fig = plt.figure()\n",
    "# #qq plot\n",
    "# res = stats.probplot(train_data['SalePrice'], plot=plt)\n",
    "# #applying log transformation\n",
    "# train_data['SalePrice'] = np.log(train_data['SalePrice'])\n",
    "# print(\"Skewness: %f\" % train_data['SalePrice'].skew())\n",
    "# print(\"Kurtosis: %f\" % train_data['SalePrice'].kurt())\n",
    "# sns.distplot(train_data['SalePrice'], fit=norm);\n",
    "# fig = plt.figure()\n",
    "# #qq plot\n",
    "# res = stats.probplot(train_data['SalePrice'], plot=plt)\n",
    "\n",
    "#3.3 convert numerical variables to categorical variables\n",
    "train_data = train_data.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n",
    "                      })\n",
    "\n",
    "#export data\n",
    "train_data.to_csv(\"tes_clean_teacher.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               skewness\n",
      "Utilities      0.999315\n",
      "Street         0.995890\n",
      "Condition2     0.989726\n",
      "RoofMatl       0.982192\n",
      "Heating        0.978082\n",
      "LandSlope      0.946575\n",
      "CentralAir     0.934932\n",
      "Functional     0.931507\n",
      "PavedDrive     0.917808\n",
      "Electrical     0.914384\n",
      "LandContour    0.897945\n",
      "ExterCond      0.878082\n",
      "SaleType       0.867808\n",
      "Condition1     0.863014\n",
      "BldgType       0.835616\n",
      "SaleCondition  0.820548\n",
      "MSZoning       0.788356\n",
      "RoofStyle      0.781507\n",
      "LotConfig      0.720548\n",
      "LotShape       0.633562\n",
      "ExterQual      0.620548\n",
      "HeatingQC      0.507534\n",
      "KitchenQual    0.503425\n",
      "HouseStyle     0.497260\n",
      "Foundation     0.443151\n",
      "MSSubClass     0.367123\n",
      "Exterior1st    0.352740\n",
      "Exterior2nd    0.345205\n",
      "MoSold         0.173288\n",
      "Neighborhood   0.154110\n",
      "Numerical features : 57\n",
      "Categorical features : 22\n",
      "NAs for numerical features in train : 26262\n",
      "Remaining NAs for numerical features in train : 0\n",
      "NAs for categorical features in train : 11676\n",
      "Remaining NAs for categorical features in train : 0\n",
      "New number of features : 175\n",
      "(2919, 159)\n",
      "(2919, 159)\n"
     ]
    }
   ],
   "source": [
    "##COPYRIGHT from 仲益教育\n",
    "import sys\n",
    "sys.path.append(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/May19thVer\")\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Help_functions_v2 import sklearn_Pvalue, sklearn_adjR2, RMSE\n",
    "import numpy as np\n",
    "\n",
    "#1: import data\n",
    "train_data=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/May19thVer/train_clean_teacher.csv\")\n",
    "test_data=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/May19thVer/tes_clean_teacher.csv\")\n",
    "#2: feature engineering\n",
    "#2.1: take a closer look at the categorical features before changing to dummy\n",
    "categorical_features = train_data.select_dtypes(include = [\"object\"]).columns\n",
    "train_cat = train_data[categorical_features]\n",
    "#see what most category data are the same\n",
    "#delete highly skew category data\n",
    "pct=[]\n",
    "for ix in train_cat.columns:\n",
    "    temp=train_cat[ix].describe()\n",
    "    pct.append(temp[\"freq\"]/temp[\"count\"])\n",
    "skewData=pd.DataFrame(pct,index=train_cat.columns,columns=[\"skewness\"])\n",
    "skewData=skewData.sort_values(by=\"skewness\",ascending=False)\n",
    "print (skewData)\n",
    "train_data = train_data.drop((skewData[skewData['skewness'] >= 0.95]).index,1) \n",
    "# Sale_Price=train_data.iloc[:,80]\n",
    "# train_data=train_data.drop([\"SalePrice\"],axis=1)\n",
    "data= pd.concat([train_data,test_data], keys=['x', 'y'])#here X is training data and Y testing data\n",
    "# data=data.drop([\"Id\"],axis=1)\n",
    "#2.2: some categorical features when there is information in the order\n",
    "#Alley: Type of alley access to property\n",
    "train_data=data\n",
    "train_data=train_data.replace({\"Alley\":{\"Grvl\" : 1, \"Pave\" : 2}})\n",
    "#BsmtCond: Evaluates the general condition of the basement\n",
    "train_data=train_data.replace({\"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "#BsmtExposure: Refers to walkout or garden level walls\n",
    "train_data=train_data.replace({\"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3}})\n",
    "#BsmtFinType1: Rating of basement finished area\n",
    "train_data=train_data.replace({\"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6}})\n",
    "#BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "train_data=train_data.replace({\"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6}})\n",
    "#BsmtQual: Evaluates the height of the basement\n",
    "train_data=train_data.replace({\"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "#ExterCond: Evaluates the present condition of the material on the exterior\n",
    "train_data=train_data.replace({\"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5}})\n",
    "#ExterQual: Evaluates the quality of the material on the exterior \n",
    "train_data=train_data.replace({\"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5}})\n",
    "#FireplaceQu: Fireplace quality\n",
    "train_data=train_data.replace({\"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "#Functional: Home functionality (Assume typical unless deductions are warranted)\n",
    "train_data=train_data.replace({\"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8}})\n",
    "#HeatingQC: Heating quality and condition\n",
    "train_data=train_data.replace({\"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "#KitchenQual: Kitchen quality\n",
    "train_data=train_data.replace({\"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "#LandSlope: Slope of property\n",
    "train_data=train_data.replace({\"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3}})\n",
    "#LotShape: General shape of property\n",
    "train_data=train_data.replace({\"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4}})\n",
    "#PavedDrive: Paved driveway\n",
    "train_data=train_data.replace({\"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2}})\n",
    "\n",
    "#2.3: Simplifications of existing categorical \n",
    "train_data[\"Condition1\"] = train_data.Condition1.replace({\"RRNe\" : \"Other\", \n",
    "                                                  \"RRNn\" : \"Other\",\"PosA\" : \"Other\", \n",
    "                                                   \"RRAe\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"Electrical\"] = train_data.Electrical.replace({\"Mix\" : \"Other\", \n",
    "                                                  \"FuseP\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"Exterior1st\"] = train_data.Exterior1st.replace({\"AsphShn\" : \"Other\", \n",
    "                                                  \"CBlock\" : \"Other\",\"ImStucc\" : \"Other\", \n",
    "                                                   \"BrkComm\" : \"Other\",\"Stone\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"Exterior2nd\"] = train_data.Exterior2nd.replace({\"CBlock\" : \"Other\", \n",
    "                                                  \"AsphShn\" : \"Other\",\"Stone\" : \"Other\", \n",
    "                                                   \"Brk Cmn\" : \"Other\",\"ImStucc\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"Foundation\"] = train_data.Foundation.replace({\"Wood\" : \"Other\", \n",
    "                                                  \"Stone\" : \"Other\"\n",
    "                                                  })\n",
    "# train_data[\"GarageType\"] = train_data.GarageType.replace({\"2Types\" : \"Other\", \n",
    "#                                                   \"CarPort\" : \"Other\"\n",
    "#                                                   })\n",
    "train_data[\"HouseStyle\"] = train_data.HouseStyle.replace({\"2.5Fin\" : \"Other\", \n",
    "                                                  \"2.5Unf\" : \"Other\",\n",
    "                                                  \"1.5Unf\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"LotConfig\"] = train_data.LotConfig.replace({\"FR3\" : \"FR2\"\n",
    "                                                  })\n",
    "train_data[\"MSSubClass\"] = train_data.MSSubClass.replace({\"SC40\" : \"Other\", \n",
    "                                                  \"SC180\" : \"Other\",\n",
    "                                                  \"SC45\" : \"Other\",\n",
    "                                                  \"SC75\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"MSZoning\"] = train_data.MSZoning.replace({\"C (all)\" : \"Other\", \n",
    "                                                  \"RH\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"Neighborhood\"] = train_data.Neighborhood.replace({\"Blueste\" : \"Other\", \n",
    "                                                  \"NPkVill\" : \"Other\",\n",
    "                                                  \"Veenker\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"RoofStyle\"] = train_data.RoofStyle.replace({\"Shed\" : \"Other\", \n",
    "                                                  \"Mansard\" : \"Other\",\n",
    "                                                  \"Gambrel\" : \"Other\",\n",
    "                                                  \"Flat\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"SaleCondition\"] = train_data.SaleCondition.replace({\"AdjLand\" : \"Other\", \n",
    "                                                  \"Alloca\" : \"Other\"\n",
    "                                                  })\n",
    "train_data[\"SaleType\"] = train_data.SaleType.replace({\"Con\" : \"Other\", \n",
    "                                                  \"Oth\" : \"Other\",\n",
    "                                                  \"CWD\" : \"Other\", \"ConLI\" : \"Other\",\n",
    "                                                  \"ConLw\" : \"Other\",\"ConLD\" : \"Other\"\n",
    "                                                  })\n",
    "\n",
    "#2.4 Combinations of existing features\n",
    "# Overall quality of the house\n",
    "train_data[\"OverallGrade\"] = train_data[\"OverallQual\"] * train_data[\"OverallCond\"]\n",
    "# Overall quality of the exterior\n",
    "train_data[\"ExterGrade\"] = train_data[\"ExterQual\"] * train_data[\"ExterCond\"]\n",
    "# Overall kitchen score\n",
    "train_data[\"KitchenScore\"] = train_data[\"KitchenAbvGr\"] * train_data[\"KitchenQual\"]\n",
    "# Total number of bathrooms\n",
    "train_data[\"TotalBath\"] = train_data[\"BsmtFullBath\"] + (0.5 * train_data[\"BsmtHalfBath\"]) + \\\n",
    "train_data[\"FullBath\"] + (0.5 * train_data[\"HalfBath\"])\n",
    "train_data.drop([\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\"],axis=1)\n",
    "# Total SF for house (incl. basement)\n",
    "train_data[\"AllSF\"] = train_data[\"GrLivArea\"] + train_data[\"TotalBsmtSF\"]\n",
    "train_data.drop([\"GrLivArea\",\"TotalBsmtSF\"],axis=1)\n",
    "# Total SF for 1st + 2nd floors\n",
    "train_data[\"AllFlrsSF\"] = train_data[\"1stFlrSF\"] + train_data[\"2ndFlrSF\"]\n",
    "train_data.drop([\"1stFlrSF\",\"2ndFlrSF\"],axis=1)\n",
    "# Total SF for porch\n",
    "train_data[\"AllPorchSF\"] = train_data[\"OpenPorchSF\"] + train_data[\"EnclosedPorch\"] + \\\n",
    "train_data[\"3SsnPorch\"] + train_data[\"ScreenPorch\"]\n",
    "train_data.drop([\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\"],axis=1)\n",
    "# House completed before sale or not\n",
    "train_data[\"BoughtOffPlan\"] = train_data.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n",
    "                                                      \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n",
    "\n",
    "#2.5 Polinomial transformation (Box-Cox)\n",
    "# X^2, X^3, X^0.5, 1/X, Log(X)\n",
    "# Find most important features relative to target\n",
    "# print(\"Find most important features relative to target\")\n",
    "# corr = train_data.corr()\n",
    "# corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "# print(corr.SalePrice)\n",
    "train_data[\"OverallQual-s2\"] = train_data[\"OverallQual\"] ** 2\n",
    "train_data[\"AllSF-2\"] = train_data[\"AllSF\"] ** 2\n",
    "train_data[\"AllFlrsSF-2\"] = train_data[\"AllFlrsSF\"] ** 2\n",
    "train_data[\"GrLivArea-2\"] = train_data[\"GrLivArea\"] ** 2\n",
    "# train_data[\"SimplOverallQual-s2\"] = train_data[\"SimplOverallQual\"] ** 2\n",
    "train_data[\"ExterQual-2\"] = train_data[\"ExterQual\"] ** 2\n",
    "train_data[\"GarageCars-2\"] = train_data[\"GarageCars\"] ** 2\n",
    "train_data[\"TotalBath-2\"] = train_data[\"TotalBath\"] ** 2\n",
    "train_data[\"KitchenQual-2\"] = train_data[\"KitchenQual\"] ** 2\n",
    "\n",
    "# Differentiate numerical features and categorical features\n",
    "categorical_features = train_data.select_dtypes(include = [\"object\"]).columns\n",
    "numerical_features = train_data.select_dtypes(exclude = [\"object\"]).columns\n",
    "# numerical_features = numerical_features.drop(\"SalePrice\")\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))\n",
    "train_num = train_data[numerical_features]\n",
    "train_cat = train_data[categorical_features]\n",
    "print(\"NAs for numerical features in train : \" + str(train_num.isnull().values.sum()))\n",
    "train_num = train_num.fillna(train_num.median())\n",
    "print(\"Remaining NAs for numerical features in train : \" + str(train_num.isnull().values.sum()))\n",
    "\n",
    "#2.6 turn category features to dummy\n",
    "print(\"NAs for categorical features in train : \" + str(train_cat.isnull().values.sum()))\n",
    "train_cat = pd.get_dummies(train_cat, drop_first=True)\n",
    "print(\"Remaining NAs for categorical features in train : \" + str(train_cat.isnull().values.sum()))\n",
    "\n",
    "#2.7 join categorical and numerical features \n",
    "train_Data_New = pd.concat([train_num, train_cat], axis = 1)\n",
    "print(\"New number of features : \" + str(train_Data_New.shape[1]))\n",
    "\n",
    "#2.8 remove collinear columns\n",
    "# Create correlation matrix\n",
    "corr_matrix = train_Data_New.corr().abs()\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "# Drop features \n",
    "train_Data_New.drop(to_drop, axis=1, inplace=True)\n",
    "print(train_Data_New.shape)\n",
    "train_Data_New.to_csv(\"2919-159.csv\")\n",
    "print(train_Data_New.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2919, 161)\n",
      "(1460, 161)\n",
      "(1459, 161)\n",
      "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:4162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "##COPYRIGHT from 仲益教育\n",
    "import sys\n",
    "# sys.path.append(\"C://Users//Haipxiang He//desktop//Kaggle//Lecture 2\")\n",
    "#conda install mxltend --channel conda-forge\n",
    "#pip install package name\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "import numpy as np\n",
    "from Help_functions_v2 import sklearn_Pvalue, sklearn_adjR2, RMSE\n",
    "\n",
    "#1: import data\n",
    "train_data=pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/May19thVer/2919-159.csv\")\n",
    "print(train_data.shape)\n",
    "X=train_data.iloc[:1460]\n",
    "print(X.shape)\n",
    "Test_data=train_data[1460:]\n",
    "print(Test_data.shape)\n",
    "Test_data.drop(\"SalePrice\",axis=1,inplace=True)\n",
    "Test_data.drop(\"Id\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2919 entries, 0 to 2918\nColumns: 161 entries, Unnamed: 0 to Heating_Wall\ndtypes: float64(17), int64(143), object(1)\nmemory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train : (2043, 159)\nX_test : (876, 159)\ny_train : (2043,)\ny_test : (876,)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'x'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e441ecb90e33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#2.1.1 select top 20 features with the best F-stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX_scored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX_scored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mfeat_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_scored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \"\"\"\n\u001b[0;32m--> 344\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n\u001b[0m\u001b[1;32m    345\u001b[0m                                    multi_output=True)\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'x'"
     ]
    }
   ],
   "source": [
    "#2.1: feature selection with p_value\n",
    "train_data.index=train_data[\"Id\"]\n",
    "train_data.drop(\"Id\", axis=1, inplace=True)\n",
    "dependentV=train_data[\"SalePrice\"]\n",
    "train_data.drop(\"SalePrice\", axis=1, inplace=True)\n",
    "#Partition the dataset in train + validation sets\n",
    "#usually linear regression needs at least 30 observations\n",
    "#split of train and validation can be 70:30, or 60:40\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, dependentV, test_size = 0.3, random_state = 0)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))\n",
    "\n",
    "#2.1.1 select top 20 features with the best F-stats\n",
    "X_scored = SelectKBest(score_func=f_regression, k=20)\n",
    "X_scored.fit(X_train, y_train)\n",
    "feat_list=X_scored.get_support()\n",
    "\n",
    "feature_scoring = pd.DataFrame({\n",
    "        'feature': X_train.columns[feat_list],\n",
    "        'pvalue': X_scored.pvalues_[feat_list]\n",
    "    })\n",
    "\n",
    "print(feature_scoring)\n",
    "#homework, find out the RMSE of in sample and out of sample regression of the top 20 selected features\n",
    "\n",
    "#2.1.2 select all features with individual p_value <=0.05\n",
    "X_scored2 = SelectKBest(score_func=f_regression, k='all').fit(X_train, y_train)\n",
    "\n",
    "feature_scoring2 = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'pvalue': X_scored2.pvalues_\n",
    "    })\n",
    "feat_pvalue_significant=feature_scoring[feature_scoring2.pvalue<=0.05]\n",
    "feat_pvalue_significant['feature'].values\n",
    "\n",
    "#2.1.3 select N features based on the \n",
    "#2.2 feature selection based on forward/backward elimination based on R Square\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "#2.2.1 find the best k features using stepforward method\n",
    "stepforward = SFS(LinearRegression(), \n",
    "           k_features=10, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=0)\n",
    "stepforward = stepforward.fit(np.array(X_train), y_train)\n",
    "print(X_train.columns[list(stepforward.k_feature_idx_)])\n",
    "#homework, find out the RMSE of in sample and out of sample regression of selected features \n",
    "#using forward elimination\n",
    "\n",
    "#2.2.2 find the best k features using stepbackward method\n",
    "backward = SFS(LinearRegression(), \n",
    "           k_features=10, \n",
    "           forward=False, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=0)\n",
    "backward = stepforward.fit(np.array(X_train), y_train)\n",
    "print(X_train.columns[list(backward.k_feature_idx_)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "in-sample r-squared is\n",
      "0.8948120661976421\n",
      "RMSE is of in-sample\n",
      "0.09253156330346547\n",
      "out-of-sample r-squared is\n",
      "0.8659982252684256\n",
      "RMSE is out-of-sample\n",
      "0.10110330408167235\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.42866e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    }
   ],
   "source": [
    "#3 feature selection with regularization\n",
    "#3.1 Ridge Regularization\n",
    "ridge_model=Ridge(alpha=1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_trainPred=ridge_model.predict(X_train)\n",
    "#in sample\n",
    "print(\"in-sample r-squared is\")\n",
    "print(r2_score(y_train, y_trainPred))\n",
    "print (\"RMSE is of in-sample\")\n",
    "print(RMSE(y_trainPred,y_train))\n",
    "#out of sample\n",
    "y_testPred=ridge_model.predict(X_test)\n",
    "print(\"out-of-sample r-squared is\")\n",
    "print(r2_score(y_test, y_testPred))\n",
    "print (\"RMSE is out-of-sample\")\n",
    "print(RMSE(y_testPred,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model_preRidge=ridge_model.predict(Test_data)\n",
    "y_model_prerfc=y_model_preRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model_prerfc=np.around(y_model_prerfc,0)\n",
    "prediction=np.array(y_model_prerfc).tolist()\n",
    "test = pd.read_csv(\"/Users/chixinning/Desktop/kaggle/KaggleMyOwn/ReferenceCode/house-prices-advanced-regression-techniques/test.csv\")\n",
    "test.insert(1,column=\"SalePrice\",value=prediction)\n",
    "predict_sub=test.drop(test.iloc[:,2:],axis=1)\n",
    "predict_sub.head()\n",
    "predict_sub.shape\n",
    "predict_sub.to_csv('Home_predictionsLassoTeacher.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdjflashdf=dfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.2 Lasso Regularization\n",
    "lasso_model=Lasso(alpha=1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_trainPred=lasso_model.predict(X_train)\n",
    "#in sample\n",
    "print(\"lasso in-sample r-squared is\")\n",
    "print(r2_score(y_train, y_trainPred))\n",
    "print (\"Lasso RMSE of in-sample is \")\n",
    "print(RMSE(y_trainPred,y_train))\n",
    "#out of sample\n",
    "y_testPred=lasso_model.predict(X_test)\n",
    "print(\"Lasso out-of-sample r-squared is\")\n",
    "print(r2_score(y_test, y_testPred))\n",
    "print (\"Lasso RMSE out-of-sample is\")\n",
    "print(RMSE(y_testPred,y_test))"
   ]
  }
 ]
}