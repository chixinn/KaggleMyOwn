# L3

## 一元回归(Simple Regression)最大的问题

模型不准，因为只选了一个特征鸭。

>  var和bias的trade-off

## Feature 变换方法

### Feature Simplification

如basement在买房时不被care,总共有多少厕所。

### Combine Features

$X_{new}=X_1\times X_2$

如人的 features: $X_1-$sex, $X_2-$size of feet.

Dummy:male:1,female:0; 

### Box-Cox变换

$X_{new}=X^n,n=-1,-2,0.5,1,2,3...$

1. Stabilize data variance

让数据更偏向normal distribution,把fat tail向中间靠拢 

2. Make data close to normal distribution

3. Improve correlation

   为什么处理x会增加和y之间的correlation呢？

> 直观确定n，或把$x^2$加进去，看了n变换后correlation有没有提高，或者看模型的整体效果有没有变好，或者看图sense去感受x和y的关系。
>
> 从x和y correlation比较高的项去尝试，去试这些项的平方之类的，看看是否会变好。
>
> Statistic is a scientific-based arts.

## Multivariate Regression

### 5 Assumptions--BLUE

1. Weak assumption：真实X和Y的关系是线性的。Linear

2. Weak assumption,除了这些features,剩下的都是噪音。Unbias

3. 所有x的方差相同：方差齐性。Best: constant of variance

4. 【重点】:Lack of perfect multicollinearity:

   Rank(X)=k, 每一列都不能被其它列线性表示。

   列满秩，full rank可逆。

   $\hat{H}=(X^TX)^{-1}X^Ty$

   如果不满秩，这个$\hat{H}$就拟合不出来了。

   > 代码中的get_dummy_function：

![IMG_BAB2550C0921-1](https://tva1.sinaimg.cn/large/008eGmZEly1gpmhh83sdlj323c0kwgyh.jpg)

> Dummy_trap:一个加了常数项，一个没加常数项。

5. 只要新的x和y的correlation不等于0，只要加进去r-square就会提高。但这样会有overfitting的问题：adjusted r-square进行惩罚。

### Adjusted R-Squared

![截屏2021-04-17 09.37.25](https://tva1.sinaimg.cn/large/008eGmZEly1gpmhqyd2b8j30cc03yq36.jpg)

## Bias-Variance Tradeoff

![截屏2021-04-17 09.42.57](https://tva1.sinaimg.cn/large/008eGmZEgy1gpmhwr1cbuj30ru0cktd4.jpg)

真实的$y_0$,$y_0=f(x_0)+\epsilon$

![截屏2021-04-17 09.43.55](https://tva1.sinaimg.cn/large/008eGmZEgy1gpmhxqjxxpj30gu0c6dh4.jpg)

我们一直想知道x和y之间真实的关系。

## 我们的目标--key of DataScience

![截屏2021-04-17 09.52.38](https://tva1.sinaimg.cn/large/008eGmZEly1gpmi6ss2zwj30ic0c6di3.jpg)